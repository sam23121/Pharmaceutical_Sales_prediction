{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_column', None)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "from ml import Ml\n",
    "from preprocess import Preprocess\n",
    "from clean_data import CleanData\n",
    "from plot import Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_date(date):\n",
    "    return datetime.strptime(date, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store = pd.read_csv(r'C:\\Users\\sam\\Desktop\\pharma\\data\\train_store.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store = pd.read_csv(r'C:\\Users\\sam\\Desktop\\pharma\\data\\test_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv(r'C:\\Users\\sam\\Desktop\\pharma\\data\\store.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Ml()\n",
    "clean = CleanData()\n",
    "pt = Plot()\n",
    "pre = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_store.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_store.drop('Unnamed: 0', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = pre.get_numerical_columns(train_store)\n",
    "print(\"the numeric columns are\",numr_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_store.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "num_col_test = pre.get_numerical_columns(test_store)\n",
    "print(\"the numeric columns are\",num_col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_col = pre.get_categorical_columns(train_store)\n",
    "print(\"the Categorial columns are\",cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_store.drop(cat_col, axis=1, inplace=True)\n",
    "to_one_hot_encoding = [col for col in cat_col if train_store[col].nunique() <= 10 and train_store[col].nunique() > 2]\n",
    "test_store.drop(to_one_hot_encoding, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store[\"StateHoliday\"] = train_store['StateHoliday'].map({\"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\n",
    "# test_store.astype({'StateHoliday': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_test = pre.get_categorical_columns(test_store)\n",
    "print(\"the Categorial columns are\",cat_col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.get_missing_values(train_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the missing values had been dealt on the Clean notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.query(\"DayOfWeek == 6\")\n",
    "# df2\n",
    "### extracting new column on weekends\n",
    "train_store = train_store.assign(weekends = ((train_store.DayOfWeek ==6) | (train_store.DayOfWeek == 7)))\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store = test_store.assign(weekends = ((test_store.DayOfWeek ==6) | (test_store.DayOfWeek == 7)))\n",
    "test_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on weekdays\n",
    "train_store = train_store.assign(weekdays = ((train_store.DayOfWeek !=6) & (train_store.DayOfWeek != 7)))\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on weekdays\n",
    "test_store = test_store.assign(weekdays = ((test_store.DayOfWeek !=6) & (test_store.DayOfWeek != 7)))\n",
    "test_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on number of days to holidays\n",
    "train_store = train_store.assign(number_of_days_to_holidays = (len(train_store.StateHoliday =='0')/len(train_store.StateHoliday != '0')))\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store = test_store.assign(number_of_days_to_holidays = (len(test_store.StateHoliday =='0')/len(test_store.StateHoliday != '0')))\n",
    "test_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on number of days after holidays\n",
    "train_store = train_store.assign(number_of_days_to_holidays = (len(train_store.StateHoliday =='0')/len(train_store.StateHoliday != '0')))\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on Beginning of month, mid month and ending of month\n",
    "train_store = train_store.assign(beginning_of_month = (train_store.Day < 10) & (train_store.Day >= 1))\n",
    "train_store = train_store.assign(mid_of_month = (train_store.Day < 20) & (train_store.Day >= 10))\n",
    "train_store = train_store.assign(end_of_month = (train_store.Day <= 31) & (train_store.Day >= 20))\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extracting new column on Beginning of month, mid month and ending of month\n",
    "test_store = test_store.assign(beginning_of_month = (test_store.Day < 10) & (test_store.Day >= 1))\n",
    "test_store = test_store.assign(mid_of_month = (test_store.Day < 20) & (test_store.Day >= 10))\n",
    "test_store = test_store.assign(end_of_month = (test_store.Day <= 31) & (test_store.Day >= 20))\n",
    "test_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have add extracted the following new columns \n",
    "- by years\n",
    "- by days\n",
    "- by weeks\n",
    "- by weekdays\n",
    "- by weekends\n",
    "- by salespercustomer\n",
    "- by beginning, mid and end of the year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('auction_id', axis=1, inplace=True)\n",
    "numerical_column = train_store.select_dtypes(exclude=[\"object\", \"bool\"]).columns.tolist()\n",
    "bool_col = train_store.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "categorical_column = train_store.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "numerical_column2 = test.select_dtypes(exclude=[\"object\", \"bool\"]).columns.tolist()\n",
    "bool_col2 = test.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "categorical_column2 = test_store.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bool_col)):\n",
    "    train_store[bool_col[i]] = train_store[bool_col[i]].replace({True: 1, False: 0})\n",
    "    test_store[bool_col[i]] = test_store[bool_col[i]].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_store[\"StateHoliday\"] = train_store['StateHoliday'].map({\"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Get column names have less than 10 more than 2 unique values\n",
    "to_one_hot_encoding = [col for col in cat_col if train_store[col].nunique() <= 10]\n",
    "one_hot_encoded_columns = pd.get_dummies(train_store[to_one_hot_encoding])\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Get column names have less than 10 more than 2 unique values\n",
    "to_one_hot_encoding = [col for col in cat_col if train_store[col].nunique() <= 10]\n",
    "one_hot_encoded_columns1 = pd.get_dummies(train_store[to_one_hot_encoding])\n",
    "\n",
    "to_one_hot_encoding = [col for col in cat_col if train_store[col].nunique() <= 10]\n",
    "one_hot_encoded_columns2 = pd.get_dummies(test_store[to_one_hot_encoding])\n",
    "to_one_hot_encoding.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_columns1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.drop(['StoreType', 'Assortment', 'PromoInterval'], axis=1, inplace=True)\n",
    "train_store = pd.concat([train_store, one_hot_encoded_columns1], axis=1)\n",
    "train_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store.drop([ 'StoreType', 'Assortment', 'PromoInterval'], axis=1, inplace=True)\n",
    "test_store = pd.concat([test_store, one_hot_encoded_columns2], axis=1)\n",
    "test_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.shape, test_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging same columns together that has no impact on training\n",
    "train_store['CompetitionOpenSince'] = np.where((train_store['CompetitionOpenSinceMonth']==0) & (train_store['CompetitionOpenSinceYear']==0) , \n",
    "                                        0,(train_store.Month - train_store.CompetitionOpenSinceMonth) + \n",
    "                                       (12 * (train_store.Year - train_store.CompetitionOpenSinceYear)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging same columns together that has no impact on training\n",
    "train_store['CompetitionOpenSince'] = np.where((train_store['CompetitionOpenSinceMonth']==0) & (train_store['CompetitionOpenSinceYear']==0) , \n",
    "                                        0,(train_store.Month - train_store.CompetitionOpenSinceMonth) + \n",
    "                                       (12 * (train_store.Year - train_store.CompetitionOpenSinceYear)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting red of CompetitionOpenSinceYear and CompetitionOpenSinceMonth since they have been merged the merged columns\n",
    "del train_store['CompetitionOpenSinceYear']\n",
    "del train_store['CompetitionOpenSinceMonth']\n",
    "del train_store['CompetitionOpenSinceYear']\n",
    "del train_store['CompetitionOpenSinceMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse**.5\n",
    "    mae = mean_absolute_error(y_true,y_pred)\n",
    "#     mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return mse, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_store.drop(['Customers', 'Sales', 'SalePerCustomer'], axis = 1) \n",
    "col_name = features.columns.tolist()\n",
    "targets=np.log(train_store.Sales)\n",
    "#col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have reversed the order because the test set was the past and the train was future \n",
    "\n",
    "y_train_test, y_train, X_train_test, X_train = train_test_split(targets, features, test_size=0.80, shuffle=False)\n",
    "print (\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train_test.shape, y_train.shape, y_train_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_train['Year'], y_train, s=5, label=\"Train data\")\n",
    "plt.scatter(X_train_test['Year'], y_train_test, s=5, label=\"Test data\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"sales\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buliding a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulid a pipeline\n",
    "model_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', RandomForestRegressor(n_estimators=10, \n",
    "                             criterion='mse', \n",
    "                             max_depth=5, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                            ))])\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# df_scaled = std_scaler.fit_transform(train_store)\n",
    "# df_scaled = pd.DataFrame(df_scaled)\n",
    "# df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_absolute_error #, mean_absolute_percentage_error\n",
    "y_pred = model_pipeline.predict(X_train_test)\n",
    "mse, rmse, mae = loss_func(y_train_test, y_pred)\n",
    "print(\"the mse is {}, rmse {}, mae {} \".format(mse, rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle to serialize and deserialize\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "date = datetime.now()\n",
    "dt_string = date.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "pickle.dump(model_pipeline, open('../models/{}.pkl'.format(dt_string), 'wb'))# reconstructed = pickle.loads(pickled_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_pipeline.named_steps[\"model\"].feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint(col_name[i], ', Score: %.5f' % (v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we can see the Promo was a big factor on the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv('../data/scaled_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open('../models/25-05-2022-14-34-17.pkl','rb')\n",
    "model = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.array([50,3,3,3,3,3,33,33,33,3,3,3,3,3,3,3,3,33])\n",
    "model.predict(array.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
